{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe986d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network created with 100 nodes and 483 edges.\n",
      "\n",
      "Node-level and graph-level measures for 100 users saved to 'twitter_influencer_network_100_users_measures.csv'\n",
      "\n",
      "--- Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Simulate Twitter Interaction Data (100 users) ---\n",
    "# Define 100 hypothetical users\n",
    "num_users = 100\n",
    "users = [f\"User_{i}\" for i in range(1, num_users + 1)]\n",
    "\n",
    "# Create a list of random interactions for a larger network\n",
    "# We'll increase the number of interactions proportionally\n",
    "np.random.seed(42) # for reproducibility\n",
    "interactions_data = []\n",
    "# Simulate more interactions for a larger network (e.g., 5-6 times the number of users)\n",
    "num_interactions = 5 * num_users\n",
    "for _ in range(num_interactions):\n",
    "    source = np.random.choice(users)\n",
    "    target = np.random.choice(users)\n",
    "    if source != target: # A user can't interact with themselves\n",
    "        interactions_data.append((source, target))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_interactions = pd.DataFrame(interactions_data, columns=['Source', 'Target'])\n",
    "\n",
    "# --- 2. Build NetworkX Graph ---\n",
    "# Create a directed graph (DiGraph)\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(df_interactions.values)\n",
    "\n",
    "print(f\"Network created with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "# --- 3. Compute Node-Level and Graph-Level Measures ---\n",
    "\n",
    "in_degree_centrality = nx.in_degree_centrality(G)\n",
    "out_degree_centrality = nx.out_degree_centrality(G)\n",
    "in_degree = dict(G.in_degree())\n",
    "out_degree = dict(G.out_degree())\n",
    "total_degree = dict(G.degree())\n",
    "\n",
    "# Handle potential disconnected components for closeness centrality\n",
    "# NetworkX's closeness_centrality handles unreachable nodes by default (returns 0 or very low values)\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "try:\n",
    "    eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000, tol=1e-06) # Added tolerance for robustness\n",
    "except nx.PowerIterationFailedConvergence:\n",
    "    print(\"Eigenvector centrality did not converge for some nodes. Setting to NaN for problematic nodes.\")\n",
    "    eigenvector_centrality = {node: np.nan for node in G.nodes()} # Fallback for non-convergence\n",
    "except ValueError as e: # Handle cases where graph might be empty or disconnected for eigenvector\n",
    "    print(f\"ValueError during eigenvector centrality: {e}. Setting to NaN for all nodes.\")\n",
    "    eigenvector_centrality = {node: np.nan for node in G.nodes()}\n",
    "\n",
    "\n",
    "# Clustering Coefficient: typically computed on the undirected version for a standard definition\n",
    "node_clustering = nx.clustering(G.to_undirected())\n",
    "\n",
    "transitivity = nx.transitivity(G.to_undirected())\n",
    "reciprocity = nx.reciprocity(G)\n",
    "density = nx.density(G)\n",
    "\n",
    "# --- Calculate Degree Centralization Manually ---\n",
    "N = G.number_of_nodes()\n",
    "\n",
    "# In-Degree Centralization\n",
    "max_in_degree_centrality = max(in_degree_centrality.values()) if in_degree_centrality else 0\n",
    "sum_of_diffs_in = sum(max_in_degree_centrality - in_degree_centrality[node] for node in G.nodes())\n",
    "if N > 1:\n",
    "    in_degree_centralization = sum_of_diffs_in / (N - 1)\n",
    "else:\n",
    "    in_degree_centralization = 0.0\n",
    "\n",
    "# Out-Degree Centralization\n",
    "max_out_degree_centrality = max(out_degree_centrality.values()) if out_degree_centrality else 0\n",
    "sum_of_diffs_out = sum(max_out_degree_centrality - out_degree_centrality[node] for node in G.nodes())\n",
    "if N > 1:\n",
    "    out_degree_centralization = sum_of_diffs_out / (N - 1)\n",
    "else:\n",
    "    out_degree_centralization = 0.0\n",
    "\n",
    "# --- 4. Organize Data into Pandas DataFrame ---\n",
    "df_nodes = pd.DataFrame({\n",
    "    'Node': list(G.nodes()),\n",
    "    'In_Degree': [in_degree.get(node, 0) for node in G.nodes()],\n",
    "    'Out_Degree': [out_degree.get(node, 0) for node in G.nodes()],\n",
    "    'Total_Degree': [total_degree.get(node, 0) for node in G.nodes()],\n",
    "    'In_Degree_Centrality': [in_degree_centrality.get(node, 0) for node in G.nodes()],\n",
    "    'Out_Degree_Centrality': [out_degree_centrality.get(node, 0) for node in G.nodes()],\n",
    "    'Closeness_Centrality': [closeness_centrality.get(node, 0) for node in G.nodes()],\n",
    "    'Betweenness_Centrality': [betweenness_centrality.get(node, 0) for node in G.nodes()],\n",
    "    'Eigenvector_Centrality': [eigenvector_centrality.get(node, np.nan) for node in G.nodes()],\n",
    "    'Clustering_Coefficient': [node_clustering.get(node, np.nan) for node in G.nodes()]\n",
    "})\n",
    "\n",
    "# Add graph-level measures to the first row of the DataFrame\n",
    "df_nodes_summary = df_nodes.copy()\n",
    "df_nodes_summary.loc[df_nodes_summary.index[0], 'Graph_Density'] = density\n",
    "df_nodes_summary.loc[df_nodes_summary.index[0], 'Graph_Reciprocity'] = reciprocity\n",
    "df_nodes_summary.loc[df_nodes_summary.index[0], 'Graph_Transitivity'] = transitivity\n",
    "df_nodes_summary.loc[df_nodes_summary.index[0], 'Graph_In_Degree_Centralization'] = in_degree_centralization\n",
    "df_nodes_summary.loc[df_nodes_summary.index[0], 'Graph_Out_Degree_Centralization'] = out_degree_centralization\n",
    "\n",
    "# Fill NaN for graph-level measures for other rows with an empty string for cleaner CSV\n",
    "for col in ['Graph_Density', 'Graph_Reciprocity', 'Graph_Transitivity', 'Graph_In_Degree_Centralization', 'Graph_Out_Degree_Centralization']:\n",
    "    df_nodes_summary[col] = df_nodes_summary[col].fillna('')\n",
    "\n",
    "# --- 5. Save to CSV ---\n",
    "output_csv_path = 'twitter_influencer_network_100_users_measures.csv'\n",
    "df_nodes_summary.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"\\nNode-level and graph-level measures for {num_users} users saved to '{output_csv_path}'\")\n",
    "print(\"\\n--- Analysis Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tejaswini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
